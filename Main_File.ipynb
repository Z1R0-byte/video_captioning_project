{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6234e942-c691-403f-9674-75326b211581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968d80ed-4701-42a0-b238-6da5702dd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path from which to extract the features\n",
    "# *.npy is used as it helps in extracting all the .npy files\n",
    "path = r'D:\\Video_captioning_project\\MLDS_hw2_data\\training_data\\feat\\*.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a17aa5-b85c-44ee-8313-a100ae89be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary with all the features and file names\n",
    "feature_dict = {}\n",
    "for file_path in glob.glob(path): \n",
    "    # [:-4] means we leave out .npy from the file_name\n",
    "    filename = file_path.split('\\\\')[-1][:-4]\n",
    "    feature_dict[filename] = np.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c4dc266-93e9-4448-bfff-5063c07ddf9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1450"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ba59c4-55fe-40f9-b2bf-370f645ad85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the labels\n",
    "with open(r'D:\\Video_captioning_project\\MLDS_hw2_data\\training_label.json', 'r') as f:\n",
    "    captions_dict_list = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dab3585-fff4-47d5-9449-5616f31c0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a captions dict, like the feature dict\n",
    "captions_dict = {}\n",
    "\n",
    "# the captions_dict maps the filenames to the list of captions \n",
    "for i in range(len(captions_dict_list)):\n",
    "    file_name = captions_dict_list[i][\"id\"]\n",
    "    captions_dict[file_name] = captions_dict_list[i][\"caption\"]\n",
    "\n",
    "# deleting captions_dict_list as we don't need it anymore\n",
    "del captions_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb9870-c39d-4ebe-b838-f1a15df871c1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd5ca15-2a14-4c48-a565-ae219caf8eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lowering the sentences \n",
    "for name, caption_list in captions_dict.items():\n",
    "    new_list = []\n",
    "    for caption in caption_list:\n",
    "        # we add <sos> and <eos> tokens too \n",
    "        new_list.append('<sos> '+str(caption.lower().strip('.'))+ ' <eos>')\n",
    "    captions_dict[name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357682a7-13f6-48e4-9a1a-dd7d027fa21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dictionary for glove embeddings\n",
    "word_to_vec_map = {}\n",
    "with open('glove.6B.50d.txt', 'r', encoding = 'utf-8') as f: \n",
    "    for lines in f:\n",
    "        line = lines.strip().split()\n",
    "        word = line[0]\n",
    "        word_to_vec_map[word] = np.array(line[1:], dtype = np.float64)\n",
    "f.close()\n",
    "# word_to_vec_map maps each word to its corresponding glove vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "652b456a-4afc-4b51-a794-3e7c8331b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "tokens = {}\n",
    "counter = 1\n",
    "for name, caption_list in captions_dict.items():\n",
    "    for caption in caption_list:\n",
    "        for word in caption.split():\n",
    "            if(word not in tokens):\n",
    "                # each word can now be repesented by a number ('token')\n",
    "                tokens[word] = counter \n",
    "                counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7c5cc1-aba8-4b4e-abbd-122746674965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_seq(string):\n",
    "    '''\n",
    "        arguments -->\n",
    "            string = the string which we will convert into a list of tokens\n",
    "        returns -->\n",
    "            seq = list of tokens representing each word in string\n",
    "    '''\n",
    "    seq = []\n",
    "    word_list = string.split()\n",
    "    for i in range(len(word_list)):\n",
    "        seq.append(tokens[word_list[i]])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f4e0d1-1d82-4338-9c35-20045f21fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to seq and finding max length (MAX_LEN)\n",
    "MAX_LEN = 0\n",
    "for name, caption_list in captions_dict.items():\n",
    "    seq_list = []\n",
    "    for caption in caption_list:\n",
    "        # converting each caption to a sequence\n",
    "        seq = text_to_seq(caption)\n",
    "        # logic for calculating MAX_LEN \n",
    "        if(len(seq)>MAX_LEN):\n",
    "            MAX_LEN = len(seq)\n",
    "        seq_list.append(seq)\n",
    "        \n",
    "    # mapping the filename to the sequence representing a caption\n",
    "    captions_dict[name] = seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c359bda4-6f4a-45ab-8abe-a67f1f101dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625eb38e-8a6d-404a-bd66-6bd2ada444c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing additional libraries to create the input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6dd5f-199f-4b00-9129-ba75aad16d23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb0cd5a7-5a26-4892-852d-9666eb24f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating input_output pairs in batches because it throws a memory error without batches\n",
    "def batch_generator(feature_dict, captions_dict, batch_size, start_index):\n",
    "    '''\n",
    "        arguments -->\n",
    "            feature_dict = a dictionary mapping file names to feature vectors\n",
    "            captions_dict = a dictionary mapping file names to caption list\n",
    "            batch_size = number of 'file names' we take \n",
    "            start_index = the index from which to start the batch\n",
    "        returns -->\n",
    "            X_batch = a numpy array containing all the feature vetors \n",
    "                    corresponding to input\n",
    "            y_in_batch = a numpy array containing the input seq\n",
    "            y_out_batch = a numpy array containing the output seq\n",
    "            next_index = the index where the next batch should start from\n",
    "    '''\n",
    "    # initializing the input and output lists\n",
    "    X_batch = []\n",
    "    y_in_batch = []\n",
    "    y_out_batch = []\n",
    "    \n",
    "    for i in range(start_index, start_index+batch_size):\n",
    "        for seq in list(captions_dict.values())[i]:\n",
    "            for k in range(1, len(seq)):\n",
    "                X_batch.append(feature_dict[list(captions_dict.keys())[i]])\n",
    "                \n",
    "                # taking the first k tokens as input\n",
    "                in_seq = [seq[:k]]\n",
    "                # using the (k+1) token as output\n",
    "                out_seq = [seq[k]]\n",
    "                \n",
    "                # padding 0 at the end of sequences for sequences that are shorter than MAX_LEN\n",
    "                in_seq = pad_sequences(in_seq, maxlen = MAX_LEN, padding = 'post', truncating='post')\n",
    "                \n",
    "                # converting our output into categorical variables\n",
    "                # here we use len(tokens)+1 as the '0' is specifically used for padding, and\n",
    "                # hence we cannot use it to represent words\n",
    "                out_seq = to_categorical(out_seq, num_classes=len(tokens)+1)\n",
    "                \n",
    "                # appending out input and output to a list\n",
    "                y_in_batch.append(in_seq)\n",
    "                y_out_batch.append(out_seq)\n",
    "          \n",
    "    # calculating next_index\n",
    "    next_index = start_index+batch_size\n",
    "    \n",
    "    return np.array(X_batch),  np.array(y_in_batch), np.array(y_out_batch) , next_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef818f-9d03-4a09-a1b1-74c3a3064734",
   "metadata": {},
   "source": [
    "# Creating the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56d6744c-9436-4c5c-b1a7-d17d253cb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(vocabulary_dict, word_to_vec_map):\n",
    "    '''\n",
    "        arguments -->\n",
    "            vocabulary_dict = a dict mapping words to tokens\n",
    "            word_to_vec_map = a dict mapping words to glove embeddings\n",
    "        returns -->\n",
    "            embedding_matrix = a numpy array that can be used as an embedding matrix to the model\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(vocabulary_dict)\n",
    "    dimensions = len(list(word_to_vec_map.values())[0])\n",
    "    \n",
    "    # initializing it to all zeros\n",
    "    embedding_matrix = np.zeros(shape = (vocab_size+1, dimensions))\n",
    "    \n",
    "    for word, i in vocabulary_dict.items():\n",
    "        embedding_vector = word_to_vec_map.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return np.array(embedding_matrix)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d51d4773-6c30-4e12-a13f-cc3fbefd1650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# storing our matrix into embed\n",
    "embed = create_embedding_matrix(tokens, word_to_vec_map)\n",
    "# deleting word_to_vec_map as we won't need it for training anymore.\n",
    "del  word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38e67416-292e-4177-82d9-dc8d159187c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6451, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30959b27-4ba2-4a1a-9eb0-cec88d8b1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from here the basic idea is to train a model taking inputs in batches, then use the weights\n",
    "# learned to decode the testing set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
