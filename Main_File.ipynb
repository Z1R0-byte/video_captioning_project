{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6234e942-c691-403f-9674-75326b211581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968d80ed-4701-42a0-b238-6da5702dd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path from which to extract the features\n",
    "# *.npy is used as it helps in extracting all the .npy files\n",
    "path = r'D:\\Video_captioning_project\\MLDS_hw2_data\\training_data\\feat\\*.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a17aa5-b85c-44ee-8313-a100ae89be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary with all the features and file names\n",
    "feature_dict = {}\n",
    "for file_path in glob.glob(path):\n",
    "    filename = file_path.split('\\\\')[-1][:-4]\n",
    "    feature_dict[filename] = np.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c4dc266-93e9-4448-bfff-5063c07ddf9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1450"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ba59c4-55fe-40f9-b2bf-370f645ad85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the labels\n",
    "with open(r'D:\\Video_captioning_project\\MLDS_hw2_data\\training_label.json', 'r') as f:\n",
    "    captions_dict_list = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dab3585-fff4-47d5-9449-5616f31c0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a captions dict, like the feature dict\n",
    "captions_dict = {}\n",
    "for i in range(len(captions_dict_list)):\n",
    "    file_name = captions_dict_list[i][\"id\"]\n",
    "    captions_dict[file_name] = captions_dict_list[i][\"caption\"]\n",
    "    \n",
    "del captions_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb9870-c39d-4ebe-b838-f1a15df871c1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd5ca15-2a14-4c48-a565-ae219caf8eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lowering the sentences\n",
    "for name, caption_list in captions_dict.items():\n",
    "    new_list = []\n",
    "    for caption in caption_list:\n",
    "        new_list.append('<sos> '+str(caption.lower().strip('.'))+ ' <eos>')\n",
    "    captions_dict[name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357682a7-13f6-48e4-9a1a-dd7d027fa21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dictionary for glove embeddings\n",
    "word_to_vec_map = {}\n",
    "with open('glove.6B.50d.txt', 'r', encoding = 'utf-8') as f: \n",
    "    for lines in f:\n",
    "        line = lines.strip().split()\n",
    "        word = line[0]\n",
    "        word_to_vec_map[word] = np.array(line[1:], dtype = np.float64)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "652b456a-4afc-4b51-a794-3e7c8331b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "tokens = {}\n",
    "counter = 0\n",
    "for name, caption_list in captions_dict.items():\n",
    "    for caption in caption_list:\n",
    "        for word in caption.split():\n",
    "            if(word not in tokens):\n",
    "                tokens[word] = counter\n",
    "                counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7c5cc1-aba8-4b4e-abbd-122746674965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_seq(string):\n",
    "    seq = []\n",
    "    word_list = string.split()\n",
    "    for i in range(len(word_list)):\n",
    "        seq.append(tokens[word_list[i]])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f4e0d1-1d82-4338-9c35-20045f21fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to seq and finding max length\n",
    "MAX_LEN = 0\n",
    "for name, caption_list in captions_dict.items():\n",
    "    seq_list = []\n",
    "    for caption in caption_list:\n",
    "        seq = text_to_seq(caption)\n",
    "        if(len(seq)>MAX_LEN):\n",
    "            MAX_LEN = len(seq)\n",
    "        seq_list.append(seq)\n",
    "    captions_dict[name] = seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c359bda4-6f4a-45ab-8abe-a67f1f101dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "642f7410-029a-4e32-8d8d-aaa5dd49aab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb0cd5a7-5a26-4892-852d-9666eb24f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating input_output pairs in batches because it throws a memory error without batches\n",
    "def batch_generator(feature_dict, captions_dict, batch_size, start_index):\n",
    "    '''\n",
    "        parameters -->\n",
    "            feature_dict = a dictionary mapping file names to feature vectors\n",
    "            captions_dict = a dictionary mapping file names to caption list\n",
    "            batch_size = number of 'file names' we take \n",
    "            start_index = the index from which to start the batch\n",
    "        returns -->\n",
    "            X_batch = a numpy array containing all the feature vetors \n",
    "                    corresponding to input\n",
    "            y_in_batch = a numpy array containing the input seq\n",
    "            y_out_batch = a numpy array containing the output seq\n",
    "    '''\n",
    "    X_batch = []\n",
    "    y_in_batch = []\n",
    "    y_out_batch = []\n",
    "    \n",
    "    for i in range(start_index, start_index+batch_size):\n",
    "        for seq in list(captions_dict.values())[i]:\n",
    "            for k in range(len(seq)):\n",
    "                X_batch.append(feature_dict[list(captions_dict.keys())[i]])\n",
    "                \n",
    "                in_seq = [seq[:k]]\n",
    "                out_seq = [seq[k]]\n",
    "                \n",
    "                in_seq = pad_sequences(in_seq, maxlen = MAX_LEN, padding = 'post', truncating='post')\n",
    "                out_seq = to_categorical(out_seq, num_classes=len(tokens))\n",
    "                \n",
    "                y_in_batch.append(in_seq)\n",
    "                y_out_batch.append(out_seq)\n",
    "                \n",
    "    next_index = start_index+batch_size\n",
    "    \n",
    "    return np.array(X_batch),  np.array(y_in_batch), np.array(y_out_batch) , next_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0a8304a-fc95-4050-b02d-3c07f456e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(vocabulary_dict, word_to_vec_map):\n",
    "    vocab_size = len(vocabulary_dict)\n",
    "    dimensions = len(list(word_to_vec_map.values())[0])\n",
    "    \n",
    "    embedding_matrix = np.zeros(shape = (vocab_size, dimensions))\n",
    "    \n",
    "    for word, i in vocabulary_dict.items():\n",
    "        embedding_vector = word_to_vec_map.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return np.array(embedding_matrix)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d51d4773-6c30-4e12-a13f-cc3fbefd1650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed = create_embedding_matrix(tokens, word_to_vec_map)\n",
    "del  word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01b01e11-1982-4dd5-a256-0045ae8e4b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6450, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e67416-292e-4177-82d9-dc8d159187c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
